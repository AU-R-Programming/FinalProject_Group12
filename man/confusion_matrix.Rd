% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/BinaryOptimizationFunctions.R
\name{confusion_matrix}
\alias{confusion_matrix}
\title{Confusion Matrix and Classification Metrics}
\usage{
confusion_matrix(y, y_pred)
}
\arguments{
\item{y}{A numeric vector of actual binary response variables (0 or 1).}

\item{y_pred}{A numeric vector of predicted binary classifications (0 or 1).}
}
\value{
A list containing:
\item{ConfusionMatrix}{A 2x2 matrix representing the confusion matrix, with rows corresponding to predicted classes and columns to actual classes.}
\item{Metrics}{A list of classification metrics, including:
\itemize{
  \item Prevalence: Proportion of positive cases in the actual data.
  \item Accuracy: Overall proportion of correctly classified observations.
  \item Sensitivity: True positive rate or recall.
  \item Specificity: True negative rate.
  \item FDR: False discovery rate.
  \item DOR: Diagnostic odds ratio.
}}
}
\description{
Computes a confusion matrix and associated classification metrics for evaluating the performance of binary classification models.
}
\examples{
# Example actual and predicted values
y <- c(1, 0, 1, 1, 0, 0, 1)
y_pred <- c(1, 0, 1, 0, 0, 1, 1)
confusion_matrix(y, y_pred)
}
